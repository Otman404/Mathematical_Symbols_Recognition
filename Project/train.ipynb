{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras import backend as K\n",
    "from myModel.model import VGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import pydot\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments (for command line)\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", # --dataset : The path to our dataset. add required=True if you want\n",
    "\thelp=\"path to input dataset (i.e., directory of images)\")\n",
    "ap.add_argument(\"-m\", \"--model\", # --model : The path to our output serialized Keras model.\n",
    "\thelp=\"path to output model\")\n",
    "ap.add_argument(\"-l\", \"--labelbin\", # --labelbin : The path to our output multi-label binarizer object.\n",
    "\thelp=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\", # --plot : The path to our output plot of training loss and accuracy.\n",
    "\thelp=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize parametres\n",
    "\n",
    "EPOCHS = 12\n",
    "BS = 100 #Batch size\n",
    "LR = 1e-3 #Learning rate 0.001\n",
    "img_dim = (45,45,3)\n",
    "train_data_dir = 'splited_dataset/train'\n",
    "test_data_dir = 'splited_dataset/test'\n",
    "labels = []\n",
    "#Nbr of training images\n",
    "train_samples_nbr  = sum(len(files) for _, _, files in os.walk(r'splited_dataset/train'))\n",
    "#Nbr of testing images\n",
    "test_samples_nbr  = sum(len(files) for _, _, files in os.walk(r'splited_dataset/test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infos about our Dataset\n",
    "nbr_of_pictures = []\n",
    "\n",
    "labels = os.listdir(\"data/extracted_images\")\n",
    "for _, _, files in os.walk(r'data/extracted_images'):\n",
    "    nbr_of_pictures.append(len(files))\n",
    "\n",
    "nbr_of_pictures=nbr_of_pictures[1:]\n",
    "#print nbr of pictures in every class\n",
    "print(\"Number of samples in every class ...\")\n",
    "for i in range(82):  # 82 : Nbr of classes\n",
    "    print(labels[i],\" : \",nbr_of_pictures[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking image data format\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (img_dim[2], img_dim[0], img_dim[1])\n",
    "else:\n",
    "    input_shape = (img_dim[0], img_dim[1], img_dim[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "# print(\"[INFO] loading images...\")\n",
    "#imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))\n",
    "# imagePaths = sorted(list(paths.list_images(train_data_dir)))\n",
    "#imagePaths = sorted(list(paths.list_images(\"data/extracted_images\")))\n",
    "# random.seed(42)\n",
    "# random.shuffle(imagePaths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = [ item for item in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, item)) ]\n",
    "# labels.append(label)\n",
    "print(len(labels),\" Classes : \",labels)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the labels using scikit-learn's special multi-label\n",
    "# binarizer implementation\n",
    "print(\"[INFO] class labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model \n",
    "model = VGGNet.build(\n",
    "\twidth=img_dim[1], height=img_dim[0],\n",
    "\tdepth=img_dim[2], classes=82,\n",
    "    activFct=\"softmax\") #for multi-class classification\n",
    "model.summary()\n",
    "print('Number of layers of our model : ',len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model \n",
    "\n",
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "#opt = RMSprop(lr=LR, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    featurewise_center=False,# set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0.0,  # randomly rotate images in the range (deg 0 to 180)\n",
    "    width_shift_range=0.0,  # randomly shift images horizontally\n",
    "    height_shift_range=0.0,  # randomly shift images vertically\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False\n",
    "    )\n",
    "\n",
    "# data augmentation for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_dim[0], img_dim[1]),\n",
    "    batch_size=BS,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_dim[0], img_dim[1]),\n",
    "    batch_size=BS,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_samples_nbr // BS,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=test_samples_nbr // BS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "#model.save(args[\"model\"])\n",
    "model.save(\"model.model\")\n",
    "model.save_weights(\"weights.h5\")\n",
    "#save the multi-label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "# f = open(args[\"labelbin\"], \"wb\")\n",
    "f = open(\"labels.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(mlb))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities = model.predict_generator(validation_generator,2000)\n",
    "\n",
    "# Evaluating the model / Get Validation accuracy on sample from validation set\n",
    "scores = model.evaluate_generator(validation_generator,test_samples_nbr//BS,verbose=1) \n",
    "print(\"Accuracy = \", scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('model_accuary_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('model_loss_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Val plot\n",
    "fig1, ax_acc = plt.subplots()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model - Accuracy')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.savefig(\"train_val_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
