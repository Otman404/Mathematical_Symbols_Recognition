{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras import backend as K\n",
    "from myModel.model import VGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-d DATASET] [-m MODEL] [-l LABELBIN]\n",
      "                             [-p PLOT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Outhm\\AppData\\Roaming\\jupyter\\runtime\\kernel-802876e1-7d4d-48e4-b85a-008a0a726acc.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", # --dataset : The path to our dataset. add required=True if you want\n",
    "\thelp=\"path to input dataset (i.e., directory of images)\")\n",
    "ap.add_argument(\"-m\", \"--model\", # --model : The path to our output serialized Keras model.\n",
    "\thelp=\"path to output model\")\n",
    "ap.add_argument(\"-l\", \"--labelbin\", # --labelbin : The path to our output multi-label binarizer object.\n",
    "\thelp=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\", # --plot : The path to our output plot of training loss and accuracy.\n",
    "\thelp=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training images :  300779\n",
      "Number of Testing images :  75194\n"
     ]
    }
   ],
   "source": [
    "img_dim = (45,45,3)\n",
    "EPOCHS = 12\n",
    "train_data_dir = 'splited_dataset/train'\n",
    "test_data_dir = 'splited_dataset/test'\n",
    "BS = 32\n",
    "LR = 1e-3\n",
    "labels = []\n",
    "train_samples_nbr = file_count = sum(len(files) for _, _, files in os.walk(r'splited_dataset/train'))\n",
    "test_samples_nbr = file_count = sum(len(files) for _, _, files in os.walk(r'splited_dataset/test'))\n",
    "print(\"Number of Training images : \",train_samples_nbr)\n",
    "print(\"Number of Testing images : \",test_samples_nbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (img_dim[2], img_dim[0], img_dim[1])\n",
    "else:\n",
    "    input_shape = (img_dim[0], img_dim[1], img_dim[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "#imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))\n",
    "imagePaths = sorted(list(paths.list_images(train_data_dir)))\n",
    "#imagePaths = sorted(list(paths.list_images(\"data/extracted_images\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes :  ['!', '(', ')', '+', ',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'A', 'alpha', 'ascii_124', 'b', 'beta', 'C', 'cos', 'd', 'Delta', 'div', 'e', 'exists', 'f', 'forall', 'forward_slash', 'G', 'gamma', 'geq', 'gt', 'H', 'i', 'in', 'infty', 'int', 'j', 'k', 'l', 'lambda', 'ldots', 'leq', 'lim', 'log', 'lt', 'M', 'mu', 'N', 'neq', 'o', 'p', 'phi', 'pi', 'pm', 'prime', 'q', 'R', 'rightarrow', 'S', 'sigma', 'sin', 'sqrt', 'sum', 'T', 'tan', 'theta', 'times', 'u', 'v', 'w', 'X', 'y', 'z', '[', ']', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "l = label = [ item for item in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, item)) ]\n",
    "labels.append(l)\n",
    "print(\"Classes : \",labels[0]) #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] class labels:\n",
      "1. !\n",
      "2. (\n",
      "3. )\n",
      "4. +\n",
      "5. ,\n",
      "6. -\n",
      "7. 0\n",
      "8. 1\n",
      "9. 2\n",
      "10. 3\n",
      "11. 4\n",
      "12. 5\n",
      "13. 6\n",
      "14. 7\n",
      "15. 8\n",
      "16. 9\n",
      "17. =\n",
      "18. A\n",
      "19. C\n",
      "20. Delta\n",
      "21. G\n",
      "22. H\n",
      "23. M\n",
      "24. N\n",
      "25. R\n",
      "26. S\n",
      "27. T\n",
      "28. X\n",
      "29. [\n",
      "30. ]\n",
      "31. alpha\n",
      "32. ascii_124\n",
      "33. b\n",
      "34. beta\n",
      "35. cos\n",
      "36. d\n",
      "37. div\n",
      "38. e\n",
      "39. exists\n",
      "40. f\n",
      "41. forall\n",
      "42. forward_slash\n",
      "43. gamma\n",
      "44. geq\n",
      "45. gt\n",
      "46. i\n",
      "47. in\n",
      "48. infty\n",
      "49. int\n",
      "50. j\n",
      "51. k\n",
      "52. l\n",
      "53. lambda\n",
      "54. ldots\n",
      "55. leq\n",
      "56. lim\n",
      "57. log\n",
      "58. lt\n",
      "59. mu\n",
      "60. neq\n",
      "61. o\n",
      "62. p\n",
      "63. phi\n",
      "64. pi\n",
      "65. pm\n",
      "66. prime\n",
      "67. q\n",
      "68. rightarrow\n",
      "69. sigma\n",
      "70. sin\n",
      "71. sqrt\n",
      "72. sum\n",
      "73. tan\n",
      "74. theta\n",
      "75. times\n",
      "76. u\n",
      "77. v\n",
      "78. w\n",
      "79. y\n",
      "80. z\n",
      "81. {\n",
      "82. }\n"
     ]
    }
   ],
   "source": [
    "# binarize the labels using scikit-learn's special multi-label\n",
    "# binarizer implementation\n",
    "print(\"[INFO] class labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    " \n",
    "# loop over each of the possible class labels and show them\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "\tprint(\"{}. {}\".format(i + 1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = VGGNet.build(\n",
    "\twidth=img_dim[1], height=img_dim[0],\n",
    "\tdepth=img_dim[2], classes=82,\n",
    "    activFct=\"softmax\") #for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "#opt = RMSprop(lr=LR, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy']) #binary_crossentropy training 99% acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    featurewise_center=False,# set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=5.0,  # randomly rotate images in the range (deg 0 to 180)\n",
    "    width_shift_range=0.0,  # randomly shift images horizontally\n",
    "    height_shift_range=0.0,  # randomly shift images vertically\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False\n",
    "    )\n",
    "\n",
    "# data augmentation for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300779 images belonging to 82 classes.\n",
      "Found 75194 images belonging to 82 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_dim[0], img_dim[1]),\n",
    "    batch_size=BS,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_dim[0], img_dim[1]),\n",
    "    batch_size=BS,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "   2/9399 [..............................] - ETA: 4:16:56 - loss: 4.8791 - acc: 0.0156    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Outhm\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.140126). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  39/9399 [..............................] - ETA: 2:32:51 - loss: 4.2431 - acc: 0.0545"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_samples_nbr // BS,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=test_samples_nbr // BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "#model.save(args[\"model\"])\n",
    "model.save(\"trained_model.model\")\n",
    "model.save_weights(\"weights.h5\")\n",
    "#save the multi-label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "# f = open(args[\"labelbin\"], \"wb\")\n",
    "f = open(\"mlb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(mlb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_generator(validation_generator,2000)\n",
    "\n",
    "scores = model.evaluate_generator(validation_generator,test_samples_nbr) #1514 testing images\n",
    "print(\"Accuracy = \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax_acc = plt.subplots()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model - Accuracy')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.savefig(\"plotting.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
